/**
 * ^GPT4oRealtimeClient
 * Author: Luis Arturo Parra - Telmo AI
 * Created: 2025-01-09
 * Usage: Cliente WebRTC para GPT-4o Realtime API Azure OpenAI
 * Business Context: Conecta el c√≠rculo neum√≥rfico con GPT-4o en tiempo real
 * Relations: useNovaAudio.js, VoiceAssistant.jsx
 * Reminders: Usa ephemeral keys y WebRTC peer connection
 */

class GPT4oRealtimeClient {
  constructor() {
    this.peerConnection = null
    this.dataChannel = null
    this.audioElement = null
    this.isConnected = false
    this.sessionId = null
    this.ephemeralKey = null
    
    // ‚úÖ CONFIGURACI√ìN AZURE OPENAI - SEG√öN DOCUMENTACI√ìN OFICIAL DE AZURE
    this.RESOURCE_NAME = "aiass-mf33a6qd-eastus2.cognitiveservices.azure.com" // ‚úÖ REAL DESDE AZURE PORTAL
    this.REGION = "eastus2"
    this.DEPLOYMENT = "gpt-4o-audio-preview-2" // ‚úÖ DEPLOYMENT NAME REAL DESDE AZURE PORTAL
    this.API_VERSION = "2024-10-01-preview"
    this.REALTIME_URL = `https://${this.RESOURCE_NAME}/openai/deployments/${this.DEPLOYMENT}/realtime?api-version=${this.API_VERSION}`
    this.API_KEY = import.meta.env.VITE_AZURE_OPENAI_API_KEY || "YOUR_API_KEY_HERE"
    this.VOICE = "verse" // Recomendado por Azure para Realtime
    this.keepAliveInterval = null
    
    // Callbacks para eventos
    this.onConnected = null
    this.onDisconnected = null
    this.onError = null
    this.onAudioReceived = null
    this.onTextReceived = null
    this.onSessionReady = null
    
    console.log('üöÄ [GPT4oRealtimeClient] Initialized for Azure OpenAI eastus2')
  }

  /**
   * Conectar directamente a Azure OpenAI Realtime API
   * Seg√∫n documentaci√≥n oficial de Azure
   */
  async connectToAzureRealtime() {
    try {
      console.log('üîë [GPT4oRealtimeClient] Connecting to Azure OpenAI Realtime API...')
      console.log('üîß [GPT4oRealtimeClient] Using API key:', this.API_KEY ? `${this.API_KEY.substring(0, 10)}...` : 'NOT_FOUND')
      console.log('üîß [GPT4oRealtimeClient] Realtime URL:', this.REALTIME_URL)
      
      // Para Azure OpenAI, usamos WebSocket directamente al endpoint realtime
      const wsUrl = this.REALTIME_URL.replace('https://', 'wss://').replace('http://', 'ws://')
      
      this.websocket = new WebSocket(wsUrl, [], {
        headers: {
          "api-key": this.API_KEY,
          "OpenAI-Beta": "realtime=v1"
        }
      })

      return new Promise((resolve, reject) => {
        this.websocket.onopen = () => {
          console.log('‚úÖ [GPT4oRealtimeClient] WebSocket connected to Azure OpenAI')
          this.isConnected = true
          this.setupWebSocketHandlers()
          resolve(true)
        }

        this.websocket.onerror = (error) => {
          console.error('‚ùå [GPT4oRealtimeClient] WebSocket error:', error)
          reject(error)
        }

        this.websocket.onclose = () => {
          console.log('üîå [GPT4oRealtimeClient] WebSocket closed')
          this.isConnected = false
        }
      })
      
    } catch (error) {
      console.error('‚ùå [GPT4oRealtimeClient] Connection error:', error)
      throw error
    }
  }

  /**
   * Inicializar conexi√≥n WebRTC con GPT-4o
   */
  async connect() {
    try {
      console.log('üîå [GPT4oRealtimeClient] Starting WebRTC connection...')
      
      // 1. Obtener ephemeral key
      await this.getEphemeralKey()
      
      // 2. Crear peer connection
      this.peerConnection = new RTCPeerConnection()
      
      // 3. Configurar audio element para reproducci√≥n
      this.audioElement = document.createElement('audio')
      this.audioElement.autoplay = true
      this.audioElement.style.display = 'none'
      document.body.appendChild(this.audioElement)
      
      // 4. Manejar audio remoto del modelo
      this.peerConnection.ontrack = (event) => {
        console.log('üîä [GPT4oRealtimeClient] Received audio track from GPT-4o')
        this.audioElement.srcObject = event.streams[0]
        this.onAudioReceived?.(event.streams[0])
      }
      
      // 5. Obtener micr√≥fono del usuario
      const userMedia = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
          sampleRate: 24000
        }
      })
      
      // 6. Agregar audio track del usuario
      const audioTrack = userMedia.getAudioTracks()[0]
      this.peerConnection.addTrack(audioTrack, userMedia)
      
      // 7. Crear data channel para eventos
      this.dataChannel = this.peerConnection.createDataChannel('realtime-channel')
      this.setupDataChannel()
      
      // 8. Crear offer SDP
      const offer = await this.peerConnection.createOffer()
      await this.peerConnection.setLocalDescription(offer)
      
      // 9. Enviar offer a Azure OpenAI WebRTC endpoint
      const sdpResponse = await fetch(`${this.WEBRTC_URL}?model=${this.DEPLOYMENT}`, {
        method: "POST",
        body: offer.sdp,
        headers: {
          Authorization: `Bearer ${this.ephemeralKey}`,
          "Content-Type": "application/sdp",
        },
      })
      
      if (!sdpResponse.ok) {
        throw new Error(`WebRTC connection failed: ${sdpResponse.status}`)
      }
      
      // 10. Configurar answer SDP
      const answerSdp = await sdpResponse.text()
      const answer = { type: "answer", sdp: answerSdp }
      await this.peerConnection.setRemoteDescription(answer)
      
      this.isConnected = true
      console.log('‚úÖ [GPT4oRealtimeClient] WebRTC connection established')
      this.onConnected?.(this.sessionId)
      
      return true
      
    } catch (error) {
      console.error('‚ùå [GPT4oRealtimeClient] Connection failed:', error)
      this.onError?.(error)
      throw error
    }
  }

  /**
   * Configurar data channel para eventos del modelo
   */
  setupDataChannel() {
    this.dataChannel.addEventListener('open', () => {
      console.log('üì° [GPT4oRealtimeClient] Data channel open')
      this.updateSession()
      this.onSessionReady?.()
      // Enviar saludo inicial para comprobar flujo de respuesta
      this.createResponse()
      // Mantener viva la sesi√≥n con pings peri√≥dicos (algunos entornos cierran el DC por inactividad)
      this.keepAliveInterval = setInterval(() => {
        if (this.dataChannel && this.dataChannel.readyState === 'open') {
          try { this.dataChannel.send(JSON.stringify({ type: 'ping', timestamp: Date.now() })) } catch {}
        }
      }, 15000)
    })

    this.dataChannel.addEventListener('message', (event) => {
      try {
        const realtimeEvent = JSON.parse(event.data)
        console.log('üì• [GPT4oRealtimeClient] Received event:', realtimeEvent.type)
        
        switch (realtimeEvent.type) {
          case "session.created":
            console.log('‚úÖ [GPT4oRealtimeClient] Session created successfully')
            break
            
          case "session.updated":
            console.log('‚úÖ [GPT4oRealtimeClient] Session updated')
            break
            
          case "conversation.item.created":
            console.log('üí¨ [GPT4oRealtimeClient] Conversation item created')
            break
            
          case "response.audio.delta":
            // Audio chunks are handled via WebRTC track, not data channel
            console.log('üîä [GPT4oRealtimeClient] Audio delta received')
            break
            
          case "response.text.delta":
            console.log('üí¨ [GPT4oRealtimeClient] Text delta:', realtimeEvent.delta)
            this.onTextReceived?.(realtimeEvent.delta)
            break
            
          case "response.done":
            console.log('üèÅ [GPT4oRealtimeClient] Response completed')
            break
            
          case "error":
            console.error('‚ùå [GPT4oRealtimeClient] Model error:', realtimeEvent.error)
            this.onError?.(realtimeEvent.error)
            break
            
          default:
            console.log('üìã [GPT4oRealtimeClient] Unknown event:', realtimeEvent.type)
        }
      } catch (error) {
        console.error('‚ùå [GPT4oRealtimeClient] Event parsing error:', error)
      }
    })

    this.dataChannel.addEventListener('close', () => {
      console.log('üì° [GPT4oRealtimeClient] Data channel closed')
      this.isConnected = false
      if (this.keepAliveInterval) {
        clearInterval(this.keepAliveInterval)
        this.keepAliveInterval = null
      }
      this.onDisconnected?.('Data channel closed')
    })
  }

  /**
   * Actualizar configuraci√≥n de sesi√≥n
   */
  updateSession() {
    if (!this.dataChannel || this.dataChannel.readyState !== 'open') {
      console.warn('‚ö†Ô∏è [GPT4oRealtimeClient] Data channel not ready for session update')
      return
    }
    
    const event = {
      type: "session.update",
      session: {
        instructions: "Eres Nova, un asistente de voz inteligente y amigable. Responde de manera natural y conversacional en espa√±ol. Mant√©n tus respuestas concisas pero informativas. Tienes una personalidad c√°lida y servicial.",
        voice: this.VOICE,
        input_audio_format: "pcm16",
        output_audio_format: "pcm16",
        turn_detection: {
          type: "server_vad",
          threshold: 0.5,
          prefix_padding_ms: 300,
          silence_duration_ms: 800,
          create_response: true,
          interrupt_response: true
        },
        temperature: 0.7,
        max_response_output_tokens: 400
      }
    }
    
    this.dataChannel.send(JSON.stringify(event))
    console.log('üì§ [GPT4oRealtimeClient] Session updated with Nova personality')
  }

  /**
   * Enviar evento de respuesta manual (para iniciar conversaci√≥n)
   */
  createResponse() {
    if (!this.dataChannel || this.dataChannel.readyState !== 'open') {
      console.warn('‚ö†Ô∏è [GPT4oRealtimeClient] Data channel not ready for response creation')
      return
    }
    
    const event = {
      type: "response.create",
      response: {
        modalities: ["audio"],
        instructions: "Saluda al usuario de manera amigable y pregunta c√≥mo puedes ayudarle hoy."
      }
    }
    
    this.dataChannel.send(JSON.stringify(event))
    console.log('üì§ [GPT4oRealtimeClient] Response creation requested')
  }

  /**
   * Desconectar de GPT-4o Realtime API
   */
  disconnect() {
    try {
      console.log('üîå [GPT4oRealtimeClient] Disconnecting...')
      
      if (this.dataChannel) {
        this.dataChannel.close()
        this.dataChannel = null
      }
      
      if (this.peerConnection) {
        this.peerConnection.close()
        this.peerConnection = null
      }
      
      if (this.audioElement) {
        this.audioElement.remove()
        this.audioElement = null
      }
      
      this.isConnected = false
      this.sessionId = null
      this.ephemeralKey = null
      
      console.log('‚úÖ [GPT4oRealtimeClient] Disconnected successfully')
      
    } catch (error) {
      console.error('‚ùå [GPT4oRealtimeClient] Disconnect error:', error)
    }
  }

  /**
   * Configurar callbacks para eventos
   */
  setCallbacks({
    onConnected,
    onDisconnected, 
    onError,
    onAudioReceived,
    onTextReceived,
    onSessionReady
  }) {
    this.onConnected = onConnected
    this.onDisconnected = onDisconnected
    this.onError = onError
    this.onAudioReceived = onAudioReceived
    this.onTextReceived = onTextReceived
    this.onSessionReady = onSessionReady
  }

  /**
   * Obtener estado de conexi√≥n
   */
  getConnectionStatus() {
    return {
      isConnected: this.isConnected,
      sessionId: this.sessionId,
      hasEphemeralKey: !!this.ephemeralKey,
      dataChannelState: this.dataChannel?.readyState || 'none',
      peerConnectionState: this.peerConnection?.connectionState || 'none'
    }
  }
}

export default GPT4oRealtimeClient
